{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering-exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " **Importing libraries**"
      ],
      "metadata": {
        "id": "f0zAj4mzb8rW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "16Embc4Gawcw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import ntpath\n",
        "import cv2\n",
        "import os, glob, shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scanning Images from the ORL folder**"
      ],
      "metadata": {
        "id": "DI1U7BHMcF8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GIKChq2jp5V9"
      },
      "outputs": [],
      "source": [
        "num_of_clusters = 41\n",
        "data_dir = '/content/sample_data/ORL'\n",
        "glob_dir = data_dir + '/*.jpg'\n",
        "\n",
        "images = [cv2.imread(file) for file in glob.glob(glob_dir)]\n",
        "paths = [file for file in glob.glob(glob_dir)]\n",
        "images = np.array(np.reshape(images, (len(images), -1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KMEANS Algorithm**"
      ],
      "metadata": {
        "id": "yLRD5Dv_cMCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters = num_of_clusters, random_state=345)\n",
        "kmeans.fit(images)\n",
        "kpredictions = kmeans.predict(images)\n",
        "result = kpredictions"
      ],
      "metadata": {
        "id": "VcZg0ctDbqgg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DBSCAN Algorithm**"
      ],
      "metadata": {
        "id": "BE5YTLMocQn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbscan = DBSCAN(eps=4500, min_samples=10)\n",
        "dbscan.fit(images)\n",
        "result = dbscan.labels_ "
      ],
      "metadata": {
        "id": "OpnIMvebcWbk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agglomerative Algorithm**"
      ],
      "metadata": {
        "id": "r1v3wnBfcXE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Single Link"
      ],
      "metadata": {
        "id": "KbwsQ5allFhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agglomerative = AgglomerativeClustering(n_clusters=num_of_clusters, linkage='single')"
      ],
      "metadata": {
        "id": "8jfEF8C_lRne"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Complete Link"
      ],
      "metadata": {
        "id": "uD67rWi1lYQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agglomerative = AgglomerativeClustering(n_clusters=num_of_clusters, linkage='complete')"
      ],
      "metadata": {
        "id": "Udv1w1BTld4A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Average Link"
      ],
      "metadata": {
        "id": "PHfs0vnFlh5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agglomerative = AgglomerativeClustering(n_clusters=num_of_clusters, linkage='average')"
      ],
      "metadata": {
        "id": "PpzJb7iGlo6U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agglomerative.fit_predict(images)\n",
        "result = agglomerative.labels_"
      ],
      "metadata": {
        "id": "JjJco75WlXFW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collecting Images**"
      ],
      "metadata": {
        "id": "vOF7LIBhpKfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_of_clusters):\n",
        "    os.makedirs(\"cluster\" + str(i))\n",
        "    \n",
        "for i in range(len(paths)):\n",
        "    shutil.copy2(paths[i], \"cluster\" + str(result[i]))\n"
      ],
      "metadata": {
        "id": "PmaBMRuWpSqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rand Index**"
      ],
      "metadata": {
        "id": "SuE-RyjjcjaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RandIndex(clusteredData):\n",
        "  TP_and_FP = calculateTP_FP(clusteredData)\n",
        "  TP = calculateTP(clusteredData)\n",
        "  FN = 1800 - TP\n",
        "  totalClusteredData = combination(410 - np.count_nonzero(clusteredData == -1))\n",
        "  TN = totalClusteredData - (FN + TP_and_FP)\n",
        "  randIndex = (TP + TN) / totalClusteredData\n",
        "  print(f\"rand index is : {randIndex}\")\n",
        "\n",
        "def calculateTP_FP(cluster):\n",
        "  sum = 0\n",
        "  for i in range(41):\n",
        "    sum += combination(np.count_nonzero(cluster == i))\n",
        "  return sum\n",
        "\n",
        "def combination(num):\n",
        "  return (num * (num - 1)) / 2\n",
        "\n",
        "def calculateTP(data):\n",
        "  sum, c = 0, 0\n",
        "  temp = []\n",
        "  for i in range(41):\n",
        "    for j in data:\n",
        "      if i == j:\n",
        "        temp.append(c)\n",
        "      c += 1\n",
        "    sum += TPcluster(temp)\n",
        "    temp.clear()\n",
        "    c = 0\n",
        "  return sum\n",
        "    \n",
        "def TPcluster(arr):\n",
        "  temp = []\n",
        "  for i in arr:\n",
        "    person = ntpath.basename(paths[i])\n",
        "    person = person.replace(\".jpg\", \"\").split(\"_\")[1]\n",
        "    temp.append(person)\n",
        "  temp = np.bincount(temp)\n",
        "  sum = 0\n",
        "  for i in temp:\n",
        "    if i >= 2:\n",
        "      sum += combination(np.count_nonzero(temp == i))\n",
        "  return sum\n"
      ],
      "metadata": {
        "id": "7SulNFQTcmu9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithm Evaluation**"
      ],
      "metadata": {
        "id": "JZ6Caxnoh5Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RandIndex(result)"
      ],
      "metadata": {
        "id": "5La_ryfIZ3YN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455a0d8f-ee00-47e2-d982-644e86ea3e18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rand index is : 0.9244677679050629\n"
          ]
        }
      ]
    }
  ]
}